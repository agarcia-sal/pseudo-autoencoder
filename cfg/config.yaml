defaults:
  - _self_
  - problem: autoencoder
  - llm_client: openai
  - override hydra/output: local

hydra:
  job:
    name: ${problem.problem_name}
    chdir: True

# The chosen algorithm
# algorithm: greedy # other options are "direct_answer"
algorithm: greedy
model: gpt-4.1-mini # this is a hack way of solving this but this line should not be here, also, switching to gpt-4.1-mini because rate limiting
pipeline: cosmetic # options: autoencoder, cosmetic, classifier

# parameters for the data
dataset: leet_code # options: human_eval, leet_code
autoencoder_version: v0.3.0tiny
cosmetic_version: v0.1.0 # update this as more datasets for the cosmetic pipeline are created
classifier_version: 4
split: train
autoencoder_timestamp: 2025-09-18_21-00-18 # for cosmetic and classifier pipelines
cosmetic_timestamp: 2025-09-29_13-46-17 # for classifier.

# Pre-processing for the pipeline
load_previous: False # is generally set to False
load_previous_timestamp: 2025-09-13_12-15-28
previous_last_iter: 1


# Main GA loop parameters
num_iterations: 4
starting_iteration: 1 # can be adjusted to continue a previous run
rounds: 1 
evolving_encoder: False
evolving_decoder: False
evolving_cosmetic: False
evolving_classifier: False

# Main GA loop parameters
max_fe: 100 # maximum number of function evaluations
pop_size: 10 # population size for GA
# init_pop_size: 30 # initial population size for GA
init_pop_size: 25 # changing this to 25 to be less intensive on the LLM model
mutation_rate: 0.5 # mutation rate for GA
timeout: 20 # timeout for evaluation of a single code
diversify_init_pop: True # whether to diversify the initial population

# Plotting:
plotting_pipeline: False